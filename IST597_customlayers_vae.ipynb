{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST597_customlayers_vae.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMxI4Ba+0lAbkXL0oyZ3zK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_SP21/blob/main/IST597_customlayers_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5zYrSxp9d5p"
      },
      "source": [
        "# IST597 :- Custom layers and VAEs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLFys0y99dAt"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCeBeCyWAGR-"
      },
      "source": [
        "The full list of pre-existing layers can be seen in the documentation ([Keras API](https://https://www.tensorflow.org/api_docs/python/tf/keras/layers)). It includes Dense (a fully-connected layer), Conv2D (1D, 3D), RNN (GRU, LSTM ,etc), BatchNormalization, Dropout, and many others.)).\n",
        "\n",
        "Let's look at different way of defining layers using keras and how we can create custom layers if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjHPoCDBA8BP"
      },
      "source": [
        "layer = tf.keras.layers.Dense(256) # Provide number of hidden units, input shape is inferred from data\n",
        "layer = tf.keras.layers.Dense(128, input_shape=(None, 10)) # Provide input shape, if model is complex"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8mdY3j8BVQn",
        "outputId": "6ae333a5-8005-4eb5-9054-bced29f1d069"
      },
      "source": [
        "layer(tf.zeros([120, 10]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 128), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZbTFC6NBaQI",
        "outputId": "6e4d23f1-1d6e-4fba-b938-2145445998ea"
      },
      "source": [
        "layer(tf.zeros([300, 10]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(300, 128), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P_0kQ6EBpfJ",
        "outputId": "20bb20d4-f804-42a0-95c4-89aaeb53b450"
      },
      "source": [
        "layer.variables # List all trainable variables"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_1/kernel:0' shape=(10, 128) dtype=float32, numpy=\n",
              " array([[ 0.17384805,  0.00887743, -0.16459115, ..., -0.06447028,\n",
              "          0.04734226, -0.05042362],\n",
              "        [-0.12398196,  0.07531349, -0.03634003, ...,  0.16114615,\n",
              "         -0.01379983, -0.17830746],\n",
              "        [-0.15147355,  0.12569968,  0.15858577, ...,  0.1249191 ,\n",
              "         -0.10011183, -0.05716008],\n",
              "        ...,\n",
              "        [ 0.08720659,  0.08513044,  0.20336129, ...,  0.10815714,\n",
              "          0.17505272, -0.14003591],\n",
              "        [-0.12220842, -0.19252951, -0.07404573, ...,  0.01232576,\n",
              "         -0.05854933,  0.07042478],\n",
              "        [-0.07334074, -0.12588744, -0.03956997, ..., -0.04009068,\n",
              "          0.09408359, -0.01227824]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApyIjeaWByTO",
        "outputId": "b4e7188b-1495-4a3f-de21-84697afd9c86"
      },
      "source": [
        "layer.kernel, layer.bias #Check weight and biases of your model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'dense_1/kernel:0' shape=(10, 128) dtype=float32, numpy=\n",
              " array([[ 0.17384805,  0.00887743, -0.16459115, ..., -0.06447028,\n",
              "          0.04734226, -0.05042362],\n",
              "        [-0.12398196,  0.07531349, -0.03634003, ...,  0.16114615,\n",
              "         -0.01379983, -0.17830746],\n",
              "        [-0.15147355,  0.12569968,  0.15858577, ...,  0.1249191 ,\n",
              "         -0.10011183, -0.05716008],\n",
              "        ...,\n",
              "        [ 0.08720659,  0.08513044,  0.20336129, ...,  0.10815714,\n",
              "          0.17505272, -0.14003591],\n",
              "        [-0.12220842, -0.19252951, -0.07404573, ...,  0.01232576,\n",
              "         -0.05854933,  0.07042478],\n",
              "        [-0.07334074, -0.12588744, -0.03956997, ..., -0.04009068,\n",
              "          0.09408359, -0.01227824]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM9MoUfaHF8V"
      },
      "source": [
        "# Create custom layers\n",
        "Optimization is similar to layers, but provides additional control over module.\n",
        "You can create custom layers with or without trainable objects, gradient table will skip all non-trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uP0oaffB3MX",
        "outputId": "bfd105eb-ad62-4e36-a981-a1115e04740f"
      },
      "source": [
        "class IST597DenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_outputs):\n",
        "        super(IST597DenseLayer, self).__init__()\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_variable(\"kernel\",\n",
        "                                        shape=[int(input_shape[-1]),\n",
        "                                               self.num_outputs])\n",
        "\n",
        "    def call(self, input):\n",
        "        return tf.matmul(input, self.kernel)\n",
        "\n",
        "layer = IST597DenseLayer(128)\n",
        "print(layer(tf.zeros([128, 10])))\n",
        "print(layer.trainable_variables)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(128, 128), dtype=float32)\n",
            "[<tf.Variable 'is_t597dense_layer/kernel:0' shape=(10, 128) dtype=float32, numpy=\n",
            "array([[ 0.02819906, -0.04818954,  0.16358803, ...,  0.13345845,\n",
            "         0.08284844, -0.13621934],\n",
            "       [ 0.01631236, -0.11199275, -0.16245486, ...,  0.13765527,\n",
            "         0.04034512, -0.18297145],\n",
            "       [ 0.20836417, -0.17131414, -0.16536291, ..., -0.07066575,\n",
            "        -0.14961156, -0.10570343],\n",
            "       ...,\n",
            "       [-0.09772234, -0.05418049, -0.12440021, ...,  0.10492109,\n",
            "         0.16676201, -0.19784525],\n",
            "       [-0.15098298, -0.0352758 , -0.14604923, ...,  0.05535717,\n",
            "         0.00510266,  0.04808341],\n",
            "       [-0.08621376, -0.11543831, -0.09033811, ...,  0.14253582,\n",
            "         0.2072043 ,  0.20771815]], dtype=float32)>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siAhgv6vH3va"
      },
      "source": [
        "# Defining your Resnet Blocks\n",
        "Here we will see how one can implement Post-activation and pre-activation resnet blocks.\n",
        "BN + Conv + relu = one set of trainable parameters (weight and biases for Conv and mean and variance for BN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veQg6XiiDDak",
        "outputId": "c4cb70ca-ac2d-4ac6-e000-30b4096d3c97"
      },
      "source": [
        "class ResnetBlock(tf.keras.Model):\n",
        "    def __init__(self, kernel_size, filters):\n",
        "        super(ResnetBlock, self).__init__(name='')\n",
        "        filters1, filters2, filters3 = filters\n",
        "\n",
        "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
        "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv2a(input_tensor)\n",
        "        x = self.bn2a(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = self.conv2b(x)\n",
        "        x = self.bn2b(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        x = self.conv2c(x)\n",
        "        x = self.bn2c(x, training=training)\n",
        "\n",
        "        x += input_tensor\n",
        "        return tf.nn.relu(x)\n",
        "\n",
        "block = ResnetBlock(4, [64, 128, 256])\n",
        "print(block(tf.zeros([4, 64, 128, 256])))\n",
        "print([x.name for x in block.trainable_variables])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]], shape=(4, 64, 128, 256), dtype=float32)\n",
            "['resnet_block_1/conv2d_3/kernel:0', 'resnet_block_1/conv2d_3/bias:0', 'resnet_block_1/batch_normalization_3/gamma:0', 'resnet_block_1/batch_normalization_3/beta:0', 'resnet_block_1/conv2d_4/kernel:0', 'resnet_block_1/conv2d_4/bias:0', 'resnet_block_1/batch_normalization_4/gamma:0', 'resnet_block_1/batch_normalization_4/beta:0', 'resnet_block_1/conv2d_5/kernel:0', 'resnet_block_1/conv2d_5/bias:0', 'resnet_block_1/batch_normalization_5/gamma:0', 'resnet_block_1/batch_normalization_5/beta:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoaEImoVDlSN"
      },
      "source": [
        "class ResnetBlockPre(tf.keras.Model):\n",
        "    def __init__(self, kernel_size, filters):\n",
        "        super(ResnetBlockPre, self).__init__(name='')\n",
        "        filters1, filters2, filters3 = filters\n",
        "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "        \n",
        "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
        "        \n",
        "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "        \n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        \n",
        "        x = self.bn2a(input_tensor, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2a(x)\n",
        "\n",
        "        \n",
        "        x = self.bn2b(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2b(x)\n",
        "\n",
        "       \n",
        "        x = self.bn2c(x, training=training)\n",
        "        x = self.conv2c(x)\n",
        "        \n",
        "        \n",
        "        x += input_tensor\n",
        "        return tf.nn.relu(x)\n",
        "\n",
        "block = ResnetBlockPre(4, [64, 128, 256])\n",
        "print(block(tf.zeros([4, 64, 128, 256])))\n",
        "print([x.name for x in block.trainable_variables])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLoni5KmrFPD",
        "outputId": "1bf8a547-b397-44e5-a808-3c42109f006f"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "class Encoder(layers.Layer):\n",
        "  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               latent_dim=32,\n",
        "               intermediate_dim=64,\n",
        "               name='encoder',\n",
        "               **kwargs):\n",
        "    super(Encoder, self).__init__(name=name, **kwargs)\n",
        "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
        "    self.dense_mean = layers.Dense(latent_dim)\n",
        "    self.dense_log_var = layers.Dense(latent_dim)\n",
        "    self.sampling = Sampling()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense_proj(inputs)\n",
        "    z_mean = self.dense_mean(x)\n",
        "    z_log_var = self.dense_log_var(x)\n",
        "    z = self.sampling((z_mean, z_log_var))\n",
        "    return z_mean, z_log_var, z\n",
        "\n",
        "\n",
        "class Decoder(layers.Layer):\n",
        "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               original_dim,\n",
        "               intermediate_dim=64,\n",
        "               name='decoder',\n",
        "               **kwargs):\n",
        "    super(Decoder, self).__init__(name=name, **kwargs)\n",
        "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
        "    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense_proj(inputs)\n",
        "    return self.dense_output(x)\n",
        "\n",
        "\n",
        "class VariationalAutoEncoder(tf.keras.Model):\n",
        "  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               original_dim,\n",
        "               intermediate_dim=64,\n",
        "               latent_dim=32,\n",
        "               name='autoencoder',\n",
        "               **kwargs):\n",
        "    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
        "    self.original_dim = original_dim\n",
        "    self.encoder = Encoder(latent_dim=latent_dim,\n",
        "                           intermediate_dim=intermediate_dim)\n",
        "    self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var, z = self.encoder(inputs)\n",
        "    reconstructed = self.decoder(z)\n",
        "    # Add KL divergence regularization loss.\n",
        "    kl_loss = - 0.5 * tf.reduce_mean(\n",
        "        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "    self.add_loss(kl_loss)\n",
        "    return reconstructed\n",
        "\n",
        "\n",
        "original_dim = 784\n",
        "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "\n",
        "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# Iterate over epochs.\n",
        "for epoch in range(10):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, x_batch_train in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      reconstructed = vae(x_batch_train)\n",
        "      # Compute reconstruction loss\n",
        "      loss = mse_loss_fn(x_batch_train, reconstructed)\n",
        "      loss += sum(vae.losses)  # Add KLD regularization loss\n",
        "\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    loss_metric(loss)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      print('step %s: mean loss = %s' % (step, loss_metric.result()))\n",
        "\n",
        "vae.save('vae')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n",
            "step 0: mean loss = tf.Tensor(0.327975, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.1256667, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.09928435, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.089245714, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.084302716, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.08094518, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.07879122, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.077177435, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.07601723, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.074981235, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "step 0: mean loss = tf.Tensor(0.07469466, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.074030675, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.07353674, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.07305652, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.072719894, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.07232446, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.07201835, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.07172433, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.071492925, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.071223654, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "step 0: mean loss = tf.Tensor(0.071149535, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.07097229, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.070836015, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.07068661, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.07059531, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.070438586, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.07032535, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.07020096, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.07010579, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.06997794, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "step 0: mean loss = tf.Tensor(0.06994419, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.069864005, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.0698096, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.069734074, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.069692954, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06961384, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.06955049, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.06948395, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.069428705, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.06934979, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "step 0: mean loss = tf.Tensor(0.069330886, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.06928692, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.06925755, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.06920818, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.06919266, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06913835, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.06909906, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.06905664, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.06901925, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.06896605, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "step 0: mean loss = tf.Tensor(0.068952784, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.068924345, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.06890698, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.06887635, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.06886903, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06882978, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.068803124, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.068771295, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.06874813, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.06870525, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "step 0: mean loss = tf.Tensor(0.06869671, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.068676315, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.06866646, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.068646565, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.06863864, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06860909, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.06859229, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.06856741, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.068550535, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.06851726, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "step 0: mean loss = tf.Tensor(0.068509646, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.06849515, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.068488136, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.068471, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.0684699, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06844527, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.068433315, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.068414636, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.06840037, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.06837466, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "step 0: mean loss = tf.Tensor(0.068368696, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.06835813, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.06835329, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.06834136, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.06834104, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06832048, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.068310186, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.06829311, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.06828213, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.068261325, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "step 0: mean loss = tf.Tensor(0.0682568, shape=(), dtype=float32)\n",
            "step 100: mean loss = tf.Tensor(0.068249494, shape=(), dtype=float32)\n",
            "step 200: mean loss = tf.Tensor(0.068246126, shape=(), dtype=float32)\n",
            "step 300: mean loss = tf.Tensor(0.06823699, shape=(), dtype=float32)\n",
            "step 400: mean loss = tf.Tensor(0.068236224, shape=(), dtype=float32)\n",
            "step 500: mean loss = tf.Tensor(0.06821947, shape=(), dtype=float32)\n",
            "step 600: mean loss = tf.Tensor(0.06821117, shape=(), dtype=float32)\n",
            "step 700: mean loss = tf.Tensor(0.06819602, shape=(), dtype=float32)\n",
            "step 800: mean loss = tf.Tensor(0.06818782, shape=(), dtype=float32)\n",
            "step 900: mean loss = tf.Tensor(0.0681694, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: vae/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: vae/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}